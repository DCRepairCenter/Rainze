<a id="readme-top"></a>

[![Status][status-shield]][status-url]

# AI æ¨¡å— / AI Module

> AI æœåŠ¡å±‚ï¼Œæä¾› LLM è°ƒç”¨å’Œä¸‰å±‚å“åº”ç”Ÿæˆç­–ç•¥ã€‚
> AI service layer providing LLM calls and three-tier response generation.

## ğŸ“– ç›®å½• / Contents

- [å…³äºæ¨¡å— / About](#å…³äºæ¨¡å—--about)
- [æ¶æ„è®¾è®¡ / Architecture](#æ¶æ„è®¾è®¡--architecture)
- [å¿«é€Ÿå¼€å§‹ / Quick Start](#å¿«é€Ÿå¼€å§‹--quick-start)
- [API å‚è€ƒ / API Reference](#api-å‚è€ƒ--api-reference)
- [é…ç½®è¯´æ˜ / Configuration](#é…ç½®è¯´æ˜--configuration)
- [ä¾èµ–å…³ç³» / Dependencies](#ä¾èµ–å…³ç³»--dependencies)

## å…³äºæ¨¡å— / About

AI æ¨¡å—æ˜¯ Rainze çš„æ™ºèƒ½æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š

- **LLM è°ƒç”¨**: ç»Ÿä¸€çš„ API è°ƒç”¨æ¥å£ï¼Œæ”¯æŒ Anthropicã€OpenAI ç­‰
- **å“åº”ç”Ÿæˆ**: ä¸‰å±‚å“åº”ç­–ç•¥ (Tier1 æ¨¡æ¿ / Tier2 è§„åˆ™ / Tier3 LLM)
- **é…ç½®ç®¡ç†**: Pydantic é…ç½®éªŒè¯

The AI module is Rainze's intelligent core, responsible for:

- **LLM Calls**: Unified API interface supporting Anthropic, OpenAI, etc.
- **Response Generation**: Three-tier strategy (Tier1 template / Tier2 rule / Tier3 LLM)
- **Configuration**: Pydantic config validation

### æŠ€æœ¯æ ˆ / Tech Stack

* ![Python](https://img.shields.io/badge/Python-3.12+-blue)
* ![httpx](https://img.shields.io/badge/httpx-0.28+-green)
* ![Pydantic](https://img.shields.io/badge/Pydantic-2.10+-purple)

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

## æ¶æ„è®¾è®¡ / Architecture

```
ai/
â”œâ”€â”€ __init__.py              # æ¨¡å—å¯¼å‡º / Module exports
â”œâ”€â”€ exceptions.py            # å¼‚å¸¸å®šä¹‰ / Exception definitions
â”œâ”€â”€ schemas.py               # Pydantic é…ç½® / Pydantic config
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ client.py            # LLM å®¢æˆ·ç«¯æŠ½è±¡ / LLM client abstraction
â”‚   â””â”€â”€ providers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ anthropic.py     # Anthropic å®ç° / Anthropic implementation
â””â”€â”€ generation/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ strategy.py          # å“åº”ç­–ç•¥åè°ƒå™¨ / Strategy coordinator
    â”œâ”€â”€ tier1_template.py    # Tier1 æ¨¡æ¿ / Tier1 template
    â”œâ”€â”€ tier2_rule.py        # Tier2 è§„åˆ™ / Tier2 rule
    â””â”€â”€ tier3_llm.py         # Tier3 LLM / Tier3 LLM
```

### ä¸‰å±‚å“åº”ç­–ç•¥ / Three-Tier Response Strategy

```
[ç”¨æˆ·è¾“å…¥/äº‹ä»¶] â†’ [åœºæ™¯åˆ¤æ–­] â†’ [Tier é€‰æ‹©]
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                         â†“                         â†“
   [Tier 1]                  [Tier 2]                  [Tier 3]
   æ¨¡æ¿å“åº”                   è§„åˆ™ç”Ÿæˆ                  LLM ç”Ÿæˆ
   <50ms                     <100ms                   500-2000ms
```

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

## å¿«é€Ÿå¼€å§‹ / Quick Start

### å‰ç½®æ¡ä»¶ / Prerequisites

* Python 3.12+
* `ANTHROPIC_API_KEY` ç¯å¢ƒå˜é‡ / environment variable

### ä½¿ç”¨ç¤ºä¾‹ / Usage Example

```python
from rainze.ai import (
    LLMClientFactory,
    LLMProvider,
    Tier1TemplateGenerator,
    Tier2RuleGenerator,
    Tier3LLMGenerator,
    ResponseGenerator,
)

# åˆ›å»º LLM å®¢æˆ·ç«¯ / Create LLM client
client = LLMClientFactory.create(
    provider=LLMProvider.ANTHROPIC,
    api_key="your-api-key"
)

# åˆ›å»ºç”Ÿæˆå™¨ / Create generators
tier1 = Tier1TemplateGenerator()
tier2 = Tier2RuleGenerator()
tier3 = Tier3LLMGenerator(client)

# åˆ›å»ºåè°ƒå™¨ / Create coordinator
generator = ResponseGenerator(tier1, tier2, tier3)

# ç”Ÿæˆå“åº” / Generate response
response = await generator.generate(
    scene_type="conversation",
    scene_context={"topic": "weather"},
    user_input="ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
)

print(response.text)
print(response.emotion_tag)
print(response.tier_used)
```

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

## API å‚è€ƒ / API Reference

### `LLMClient`

LLM å®¢æˆ·ç«¯æŠ½è±¡åŸºç±»ã€‚

| æ–¹æ³• / Method | å‚æ•° / Args | è¿”å› / Returns | è¯´æ˜ / Description |
|---------------|-------------|----------------|---------------------|
| `generate()` | `request: LLMRequest` | `LLMResponse` | åŒæ­¥ç”Ÿæˆ / Sync generate |
| `generate_stream()` | `request: LLMRequest` | `AsyncIterator[str]` | æµå¼ç”Ÿæˆ / Stream generate |

### `ResponseGenerator`

å“åº”ç”Ÿæˆåè°ƒå™¨ã€‚

| æ–¹æ³• / Method | å‚æ•° / Args | è¿”å› / Returns | è¯´æ˜ / Description |
|---------------|-------------|----------------|---------------------|
| `generate()` | `scene_type, context, user_input` | `GeneratedResponse` | ç”Ÿæˆå“åº” / Generate response |

### `GeneratedResponse`

| å­—æ®µ / Field | ç±»å‹ / Type | è¯´æ˜ / Description |
|--------------|-------------|---------------------|
| `text` | `str` | å“åº”æ–‡æœ¬ / Response text |
| `emotion_tag` | `EmotionTag?` | æƒ…æ„Ÿæ ‡ç­¾ / Emotion tag |
| `tier_used` | `ResponseTier` | ä½¿ç”¨çš„å±‚çº§ / Tier used |
| `latency_ms` | `float` | å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰/ Latency (ms) |

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

## é…ç½®è¯´æ˜ / Configuration

é…ç½®æ–‡ä»¶: `config/api_settings.json`

```json
{
  "primary_api": {
    "provider": "anthropic",
    "api_key_env": "ANTHROPIC_API_KEY",
    "default_model": "claude-sonnet-4-20250514",
    "timeout_seconds": 30
  },
  "generation": {
    "default_temperature": 0.8,
    "default_max_tokens": 150,
    "tier3_timeout_seconds": 3
  }
}
```

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

## ä¾èµ–å…³ç³» / Dependencies

### ä¾èµ–çš„æ¨¡å— / Depends On

- `rainze.core.contracts` - EmotionTag, ResponseTier
- `rainze.core.exceptions` - RainzeError

### è¢«ä¾èµ–äº / Depended By

- `rainze.agent` - Agent å¾ªç¯è°ƒç”¨ AI æœåŠ¡
- `rainze.features` - åŠŸèƒ½æ¨¡å—ä½¿ç”¨ç”Ÿæˆèƒ½åŠ›

<p align="right">(<a href="#readme-top">è¿”å›é¡¶éƒ¨ / Back to top</a>)</p>

<!-- MARKDOWN LINKS -->
[status-shield]: https://img.shields.io/badge/Status-å¼€å‘ä¸­-yellow
[status-url]: #
